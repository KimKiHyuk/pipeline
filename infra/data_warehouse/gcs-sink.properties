name=gcs-sink
connector.class=io.confluent.connect.gcs.GcsSinkConnector
tasks.max=1

gcs.bucket.name=daangn-295304-daangn-log
gcs.part.size=5242880
flush.size=3
gcs.credentials.path=/home/key/repository/data-lake-iac/daangn-295304-1e160d209121.json
storage.class=io.confluent.connect.gcs.storage.GcsStorage

# Key converter same for both examples
key.converter=org.apache.kafka.connect.storage.StringConverter

# Avro example with orders test data
topics=orders
format.class=io.confluent.connect.gcs.format.avro.AvroFormat
value.converter=io.confluent.connect.avro.AvroConverter
value.converter.schema.registry.url=http://localhost:8081
path.format='year'=YYYY_'month'=MM_'day'=dd_'hour'=HH
schema.compatibility=NONE
partitioner.class=io.confluent.connect.storage.partitioner.DefaultPartitioner
confluent.topic.bootstrap.servers=localhost:9092
confluent.topic.replication.factor=1